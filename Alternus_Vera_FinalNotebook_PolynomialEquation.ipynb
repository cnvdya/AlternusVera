{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternus Vera - Final Notebook\n",
    "### Functions which give accuracy of news for various factors and final polynomial equation\n",
    "### Team Psychic-Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(train_df[train_df.label == 'half-true'].index)\n",
    "train_df = train_df.drop(train_df[train_df.label == 'mostly-true'].index)\n",
    "train_df = train_df.drop(train_df[train_df.label == 'barely-true'].index)\n",
    "train_df = train_df.drop(train_df[train_df.label == 'FALSE'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['label'] == 'TRUE', 'label_value'] = 0 \n",
    "train_df.loc[train_df['label'] == 'pants-fire', 'label_value'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = pd.read_csv('/Users/andrew/Documents/MS - SJSU/Fall Sem 2018/CMPE 257 - Machine Learning/liar_dataset/test_data.csv')\n",
    "test_data.columns = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_title\", \"State\", \"party_affiliation\", \"barely_true\", \"false\", \"half_true\", \"mostly_true\", \"pants_on_fire\",\"context\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(test_data[test_data.label == 'half-true'].index)\n",
    "test_data = test_data.drop(test_data[test_data.label == 'mostly-true'].index)\n",
    "test_data = test_data.drop(test_data[test_data.label == 'barely-true'].index)\n",
    "test_data = test_data.drop(test_data[test_data.label == 'FALSE'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc[test_data['label'] == 'TRUE', 'sensational_actual'] = 0 \n",
    "test_data.loc[test_data['label'] == 'pants-fire', 'sensational_actual'] = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc[test_data['label'] == 'TRUE', 'label_value'] = 0\n",
    "test_data.loc[test_data['label'] == 'pants-fire', 'label_value'] = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = train_df['statement']\n",
    "statements = list(statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "results = []\n",
    "for sentence in statements:\n",
    "    #print(sentence)\n",
    "    sentiment_score = sid.polarity_scores(sentence)\n",
    "    sentiment_score['statement'] = sentence\n",
    "    results.append(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.5106</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.069</td>\n",
       "      <td>chicago bears starting quarterbacks last 10 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>mccain opposed requirement government buy amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>says paul ryan still endorsing trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.178</td>\n",
       "      <td>federal government thinks authority regulate t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>austin city basically doubled size every 25 ye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   compound   neg    neu    pos  \\\n",
       "0   -0.5106  0.19  0.741  0.069   \n",
       "1    0.0000  0.00  1.000  0.000   \n",
       "2    0.0000  0.00  1.000  0.000   \n",
       "3    0.0772  0.00  0.822  0.178   \n",
       "4    0.0000  0.00  1.000  0.000   \n",
       "\n",
       "                                           statement  \n",
       "0  chicago bears starting quarterbacks last 10 ye...  \n",
       "1  mccain opposed requirement government buy amer...  \n",
       "2               says paul ryan still endorsing trump  \n",
       "3  federal government thinks authority regulate t...  \n",
       "4  austin city basically doubled size every 25 ye...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df = pd.DataFrame.from_records(results)\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['variation']= abs(sentiment_df['pos'] - sentiment_df['neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>statement</th>\n",
       "      <th>variation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.5106</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.069</td>\n",
       "      <td>chicago bears starting quarterbacks last 10 ye...</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>mccain opposed requirement government buy amer...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>says paul ryan still endorsing trump</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.178</td>\n",
       "      <td>federal government thinks authority regulate t...</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>austin city basically doubled size every 25 ye...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   compound   neg    neu    pos  \\\n",
       "0   -0.5106  0.19  0.741  0.069   \n",
       "1    0.0000  0.00  1.000  0.000   \n",
       "2    0.0000  0.00  1.000  0.000   \n",
       "3    0.0772  0.00  0.822  0.178   \n",
       "4    0.0000  0.00  1.000  0.000   \n",
       "\n",
       "                                           statement  variation  label  \n",
       "0  chicago bears starting quarterbacks last 10 ye...      0.121     -1  \n",
       "1  mccain opposed requirement government buy amer...      0.000      0  \n",
       "2               says paul ryan still endorsing trump      0.000      0  \n",
       "3  federal government thinks authority regulate t...      0.178      0  \n",
       "4  austin city basically doubled size every 25 ye...      0.000      0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df['label'] = 0\n",
    "sentiment_df.loc[sentiment_df['compound'] > 0.2, 'label'] = 1\n",
    "sentiment_df.loc[sentiment_df['compound'] < -0.2, 'label'] = -1\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "test_data[['sentiment_score','variation']] = sentiment_df[['label','variation']][['sentiment_score','variation']] = sentiment_df[['label','variation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_title</th>\n",
       "      <th>State</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true</th>\n",
       "      <th>false</th>\n",
       "      <th>half_true</th>\n",
       "      <th>mostly_true</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "      <th>sensational_actual</th>\n",
       "      <th>label_value</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9524.json</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>campaign-finance,legal-issues,campaign-adverti...</td>\n",
       "      <td>state-democratic-party-wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>a web video</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5962.json</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>Over the past five years the federal governmen...</td>\n",
       "      <td>federal-budget,pensions,retirement</td>\n",
       "      <td>brendan-doherty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a campaign website</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7070.json</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>Says that Tennessee law requires that schools ...</td>\n",
       "      <td>county-budget,county-government,education,taxes</td>\n",
       "      <td>stand-children-tennessee</td>\n",
       "      <td>Child and education advocacy organization.</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>in a post on Facebook.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12849.json</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>Donald Trump is against marriage equality. He ...</td>\n",
       "      <td>gays-and-lesbians,marriage</td>\n",
       "      <td>sean-patrick-maloney</td>\n",
       "      <td>Congressman for NY-18</td>\n",
       "      <td>New York</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a speech at the Democratic National Convention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11269.json</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>Denali is the Kenyan word for black power.</td>\n",
       "      <td>environment</td>\n",
       "      <td>viral-image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>an image shared on Facebook</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       label                                          statement  \\\n",
       "3    9524.json  pants-fire  When asked by a reporter whether hes at the ce...   \n",
       "4    5962.json        TRUE  Over the past five years the federal governmen...   \n",
       "5    7070.json        TRUE  Says that Tennessee law requires that schools ...   \n",
       "7   12849.json        TRUE  Donald Trump is against marriage equality. He ...   \n",
       "11  11269.json  pants-fire         Denali is the Kenyan word for black power.   \n",
       "\n",
       "                                              subject  \\\n",
       "3   campaign-finance,legal-issues,campaign-adverti...   \n",
       "4                  federal-budget,pensions,retirement   \n",
       "5     county-budget,county-government,education,taxes   \n",
       "7                          gays-and-lesbians,marriage   \n",
       "11                                        environment   \n",
       "\n",
       "                             speaker  \\\n",
       "3   state-democratic-party-wisconsin   \n",
       "4                    brendan-doherty   \n",
       "5           stand-children-tennessee   \n",
       "7               sean-patrick-maloney   \n",
       "11                       viral-image   \n",
       "\n",
       "                                 speaker_title         State  \\\n",
       "3                                          NaN     Wisconsin   \n",
       "4                                          NaN  Rhode Island   \n",
       "5   Child and education advocacy organization.     Tennessee   \n",
       "7                        Congressman for NY-18      New York   \n",
       "11                                         NaN           NaN   \n",
       "\n",
       "   party_affiliation  barely_true  false  half_true  mostly_true  \\\n",
       "3           democrat            5      7          2            2   \n",
       "4         republican            1      2          1            1   \n",
       "5               none            0      0          0            0   \n",
       "7           democrat            0      0          0            0   \n",
       "11              none            5      5          0            3   \n",
       "\n",
       "    pants_on_fire                                         context  \\\n",
       "3               7                                     a web video   \n",
       "4               0                              a campaign website   \n",
       "5               0                          in a post on Facebook.   \n",
       "7               0  a speech at the Democratic National Convention   \n",
       "11             15                     an image shared on Facebook   \n",
       "\n",
       "    sensational_actual  label_value  sentiment_score  variation  \n",
       "3                  1.0          1.0              0.0      0.178  \n",
       "4                  0.0          0.0              0.0      0.000  \n",
       "5                  0.0          0.0              1.0      0.107  \n",
       "7                  0.0          0.0             -1.0      0.333  \n",
       "11                 1.0          1.0              1.0      0.200  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts= cv.fit_transform(train_df['statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = train_df.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"variation\"], how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"variation\"], how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Weightages for  factors based on threshold value and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A Random Classifier was built to find the weightage of each factor.\n",
    "* A for loop iterates between 0 and 1 to pick the best possible threshold that would give the maximum accuracy for each factor\n",
    "* For each factor the model was trained with the factor score and label value in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensationalism Weightage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_accuracy 0.41935483870967744\n",
      "Max_threshold 0.5825825825825826\n"
     ]
    }
   ],
   "source": [
    "max_accuracy_sensationalism = 0\n",
    "max_accuracy_political_affiliation = 0\n",
    "dict_threshold = {}\n",
    "threshold_list = []\n",
    "accuracy_list = []\n",
    "X_train = train_df[['sensational_value','variation']]\n",
    "y_train = train_df['label_value']\n",
    "X_test = test_data[['sensational_actual','variation']]\n",
    "y_test = test_data['label_value']\n",
    "for thresholdsen in np.linspace(0,1,1000):\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    threshold_list.append(thresholdsen)\n",
    "    accuracy_list.append(accuracy)\n",
    "    if accuracy > max_accuracy_sensationalism:\n",
    "        max_accuracy_sensationalism = accuracy\n",
    "        max_threshold_sensationalism = thresholdsen\n",
    "print(\"Max_accuracy\",max_accuracy_sensationalism)\n",
    "print(\"Max_threshold\",max_threshold_sensationalism)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Political Affiliation Weightage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 2)\n",
      "(303,)\n",
      "(212, 2)\n",
      "(91, 2)\n",
      "(212,)\n",
      "(91,)\n",
      "Max_accuracy 0.6593406593406593\n",
      "Max_threshold 0.22322322322322322\n"
     ]
    }
   ],
   "source": [
    "dataset_sample = pd.read_csv('test_with_finalscore.csv')\n",
    "dataset_sample.head(5)\n",
    "\n",
    "X = dataset_sample[['label','republican_score','democrat_score']]\n",
    "X = X.loc[X['label'].isin(['true','pants-fire'])]\n",
    "X.loc[X['label'] == 'true', 'label_value'] = 0 \n",
    "X.loc[X['label'] == 'pants-fire', 'label_value'] = 1\n",
    "\n",
    "\n",
    "cols_of_interest = ['republican_score','democrat_score']\n",
    "\n",
    "X_doc = X[cols_of_interest]\n",
    "y = X['label_value']\n",
    "\n",
    "\n",
    "print(X_doc.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_doc, y, random_state=7,test_size = 0.3)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "max_accuracy_political_affiliation = 0\n",
    "dict_threshold = {}\n",
    "threshold_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for threshold in np.linspace(0,1,1000):\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    threshold_list.append(threshold)\n",
    "    accuracy_list.append(accuracy)\n",
    "    if accuracy > max_accuracy_political_affiliation:\n",
    "        max_accuracy_political_affiliation = accuracy\n",
    "        max_threshold_sensationalism = threshold\n",
    "print(\"Max_accuracy\",max_accuracy_political_affiliation)\n",
    "print(\"Max_threshold\",max_threshold_sensationalism)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controversy Weightage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc2vec_score</th>\n",
       "      <th>variance_level</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.563970</td>\n",
       "      <td>0.098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.662198</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020447</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.604162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc2vec_score  variance_level  label_id\n",
       "0       0.004599           0.077         0\n",
       "1       0.563970           0.098         1\n",
       "2       0.662198           0.099         0\n",
       "3       0.020447           0.394         0\n",
       "4       0.604162           0.000         1"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample_contro = pd.read_csv('output_contro.csv')\n",
    "dataset_sample_contro.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "(1000,)\n",
      "(700, 2)\n",
      "(300, 2)\n",
      "(700,)\n",
      "(300,)\n",
      "Max_accuracy 0.5166666666666667\n",
      "Max_threshold 0.2772772772772773\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = dataset_sample_contro[['label_id','Doc2vec_score','variance_level']]\n",
    "#X = X.loc[X['label'].isin(['true','pants-fire'])]\n",
    "#X.loc[X['label'] == 'true', 'label_value'] = 0 \n",
    "#X.loc[X['label'] == 'pants-fire', 'label_value'] = 1\n",
    "\n",
    "\n",
    "cols_of_interest = ['Doc2vec_score','variance_level']\n",
    "\n",
    "X_doc = X[cols_of_interest]\n",
    "y = X['label_id']\n",
    "\n",
    "\n",
    "print(X_doc.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_doc, y, random_state=7,test_size = 0.3)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "max_accuracy_controversy = 0\n",
    "dict_threshold = {}\n",
    "threshold_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for threshold in np.linspace(0,1,1000):\n",
    "\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    y_pred=clf.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    threshold_list.append(threshold)\n",
    "    accuracy_list.append(accuracy)\n",
    "    if accuracy > max_accuracy_controversy:\n",
    "        max_accuracy_controversy = accuracy\n",
    "        max_threshold_controversy= threshold\n",
    "print(\"Max_accuracy\",max_accuracy_controversy)\n",
    "print(\"Max_threshold\",max_threshold_controversy)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anjana Eldo - Sensationalism factor\n",
    "### Function to determine sensationalism score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_doc = pd.read_csv('train_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Used my sensationalism distionary to train the Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensational_words_vocab = ['assassin','attack','domest','secur','enforc','disast','nation','prepared','respons','recoveri','emerg','respond','militia','shoot','evacu','hostag','explos','crime','organ','gang','state','breach','threat','standoff','lockdown','bomb','riot','land','incid','suspici','nuclear','hazard','infect','outbreak','contamin','terror','epidem','critic','infrastructur','transport','grid','outag','disrupt','violenc','cartel','drug','narcot','shootout','traffic','kidnap','illeg','smuggl','qaeda','weapon','devic','improvis','bomber','suicid','hurrican','tornado','tsunami','earthquak','tremor','flood','storm','extrem','weather','forest','strand','wildfir','avalanch','blizzard','lighten','broadcast','cyber','ddo','denial','servic','malwar','phish','believ','support','isi','absolut','promis','societi','declar','islam','recess','price','market','stock','lotteri','sanctoin','sign','chang','climat','global','warm','kill','dead','horrifi','vicious','injur','beat','histori','polici','care','job','biographi','messag','feder','abort','energi','foreign','health','economi','educ','candid','ethic','elect','financi','bankruptci','corpor','technolog','divers','bipartisanship','consum','militari','debt','legal','homeland','deficit','iraq','patriot','campaign','water','immigr','correct','civil','crimin','hous','kagan','poverti','sexual','public','tax','poll','social','gun','incom','govern','congress','medicaid','famili','gay','disabl','debat','medicar','environ','stimulu','sport','agricultur','ebola','afghanistan','marriag','pension','children','religion','pundit','labor','veteran','israel','anim','autism','counti','welfar','trade','occupi','hunger','vote','union','bush','popul','scienc','alcohol','redistrict','transpar','marijuana','suprem','basebal','china','space','recreat','gambl','obama','food','censu','fake','congression','tourism','human','privaci','retir','women','sotomayor','urban','natur','worker','wealth','homeless','fire','death','budget','regul','busi','safeti','issu','financ','accomplish','right','justic','nomin','machin','amend','effici','wall','record','administr','advertis','spill','court','birth','cultur','news','rule','hampshir','penalti','updat','lesbian','street','certif','fact','week','colbert','report','tampa']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(sensational_words_vocab)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "\n",
    "d2v_model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "d2v_model.build_vocab(tagged_data)\n",
    "#d2v_model.train(tagged_data, total_examples=d2v_model.corpus_count, epochs=10, start_alpha=0.002, end_alpha=-0.016)\n",
    "for epoch in range(max_epochs):\n",
    "    d2v_model.train(tagged_data,\n",
    "                total_examples=d2v_model.corpus_count,\n",
    "                epochs=d2v_model.iter)\n",
    "    d2v_model.alpha -= 0.0002\n",
    "    d2v_model.min_alpha = d2v_model.alpha\n",
    "    \n",
    "d2v_model.save(\"d2v.model.pa\")\n",
    "print(\"Model Saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_statements_d2v=train_df_doc[['statement','label']]\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "texts=[]\n",
    "for x in df_train_statements_d2v['statement']:\n",
    "    texts.append(model.infer_vector(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistics Regression and Random Forrest for Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_label(x):\n",
    "    if (x == 'true' or x=='mostly-true' or x=='half-true'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "encode_label('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=pd.DataFrame(texts)\n",
    "y=df_train_statements_d2v['label'].map(lambda x:encode_label(x))\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y,test_size = .3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr_doc2Vec = LogisticRegression(C=100)\n",
    "logisticRegr_doc2Vec.fit(X_train, y_train)\n",
    "pred = logisticRegr_doc2Vec.predict(X_test)\n",
    "import pickle\n",
    "s = pickle.dumps(logisticRegr_doc2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.89      0.69       255\n",
      "          1       0.45      0.12      0.19       195\n",
      "\n",
      "avg / total       0.52      0.56      0.47       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_doc2vec = RandomForestClassifier(n_jobs=-1,n_estimators=50,max_depth=90)\n",
    "rf_doc2vec.fit(X_train,y_train)\n",
    "rf_pred = rf_doc2vec.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.89      0.71       255\n",
      "          1       0.55      0.18      0.27       195\n",
      "\n",
      "avg / total       0.57      0.58      0.52       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detetcing sensationalism for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "def detect_sensationalism_calc(news):\n",
    "    data_pred=[]\n",
    "    data_pred.append(model.infer_vector(news))\n",
    "    lrg_pa = pickle.loads(s)\n",
    "    pred_conf=lrg_pa.predict_proba(data_pred)\n",
    "    #print(pred_conf)\n",
    "    return pred_conf[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensationalismPredictor:\n",
    "    def __init__(self,news):\n",
    "        self.news=news\n",
    "    def predict(self):\n",
    "        return detect_sensationalism_calc(self.news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46212868370061505"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_sensationalism_calc(\"say anni list polit group support trimest abort demand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mudrita Chaturvedi - Political Affiliation and Political Bias Score Predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_title</th>\n",
       "      <th>State</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true</th>\n",
       "      <th>false</th>\n",
       "      <th>half_true</th>\n",
       "      <th>mostly_true</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        label                                          statement  \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
       "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                              subject         speaker         speaker_title  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "      State party_affiliation  barely_true  false  half_true  mostly_true  \\\n",
       "0     Texas        republican            0      1          0            0   \n",
       "1  Virginia          democrat            0      0          1            1   \n",
       "2  Illinois          democrat           70     71        160          163   \n",
       "3       NaN              none            7     19          3            5   \n",
       "4   Florida          democrat           15      9         20           19   \n",
       "\n",
       "   pants_on_fire              context  \n",
       "0              0             a mailer  \n",
       "1              0      a floor speech.  \n",
       "2              9               Denver  \n",
       "3             44       a news release  \n",
       "4              2  an interview on CNN  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "dataset_train = pd.read_csv('train.tsv', delimiter = '\\t', quoting = 3, header=None)\n",
    "dataset_train.columns = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_title\", \"State\", \"party_affiliation\", \"barely_true\", \"false\", \"half_true\", \"mostly_true\", \"pants_on_fire\",\"context\"]\n",
    "dataset_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andrew/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/andrew/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/andrew/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "def text_preprocessing(df_base,column):\n",
    "    df=df_base.copy()\n",
    "    # lowercase the text\n",
    "    df[column]=df[column].str.lower()\n",
    "    # word tokenization\n",
    "    df[column]=df[column].map(lambda x: nltk.word_tokenize(x))\n",
    "    # remove stop words and non alphanumeric charaters\n",
    "    df[column]=df[column].map(lambda x: [w for w in x if (not w in stop_words) and w.isalpha()])\n",
    "    # lemmatization\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    df[column]=df[column].map(lambda x: [ wordnet_lemmatizer.lemmatize(w) for w in x])    \n",
    "    # stemming\n",
    "    porter = PorterStemmer()\n",
    "    df[column]=df[column].map(lambda x: [porter.stem(w) for w in x] )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_title</th>\n",
       "      <th>State</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true</th>\n",
       "      <th>false</th>\n",
       "      <th>half_true</th>\n",
       "      <th>mostly_true</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>[say, anni, list, polit, group, support, abort...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>[declin, coal, start, start, natur, ga, took, ...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>[hillari, clinton, agre, john, mccain, vote, g...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>[health, care, reform, legisl, like, mandat, f...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>[econom, turnaround, start, end, term]</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        label                                          statement  \\\n",
       "0   2635.json        false  [say, anni, list, polit, group, support, abort...   \n",
       "1  10540.json    half-true  [declin, coal, start, start, natur, ga, took, ...   \n",
       "2    324.json  mostly-true  [hillari, clinton, agre, john, mccain, vote, g...   \n",
       "3   1123.json        false  [health, care, reform, legisl, like, mandat, f...   \n",
       "4   9028.json    half-true             [econom, turnaround, start, end, term]   \n",
       "\n",
       "                              subject         speaker         speaker_title  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "      State party_affiliation  barely_true  false  half_true  mostly_true  \\\n",
       "0     Texas        republican            0      1          0            0   \n",
       "1  Virginia          democrat            0      0          1            1   \n",
       "2  Illinois          democrat           70     71        160          163   \n",
       "3       NaN              none            7     19          3            5   \n",
       "4   Florida          democrat           15      9         20           19   \n",
       "\n",
       "   pants_on_fire              context  \n",
       "0              0             a mailer  \n",
       "1              0      a floor speech.  \n",
       "2              9               Denver  \n",
       "3             44       a news release  \n",
       "4              2  an interview on CNN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=text_preprocessing(dataset_train,'statement')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_political_affiliation=['private accounts',\n",
    "'trade agreement',\n",
    "'American people',\n",
    "'tax breaks',\n",
    "'trade deficit',\n",
    "'oil companies',\n",
    "'credit card',\n",
    "'nuclear option',\n",
    "'war in Iraq',\n",
    "'middle class',\n",
    "'President budget',\n",
    "'Republican party',\n",
    "'change the rules',\n",
    "'minimum wage',\n",
    "'budget deficit',\n",
    "'Republican senators',\n",
    "'wildlife refuge',\n",
    "'card companies',\n",
    "'worker\\'s rights',\n",
    "'poor people',\n",
    "'Republican leader',\n",
    "'cut funding',\n",
    "'American workers',\n",
    "'living in poverty',\n",
    "'Senate Republicans',\n",
    "'fuel efficiency',\n",
    "'national wildlife',\n",
    "'veterans health care',\n",
    "'congressional black caucus',\n",
    "'billion in tax cuts',\n",
    "'security trust fund',\n",
    "'social security trust',\n",
    "'privatize social security',\n",
    "'American free trade',\n",
    "'central American free',\n",
    "'corporation for public broadcasting',\n",
    "'additional tax cuts',\n",
    "'pay for tax cuts',\n",
    "'tax cuts for people',\n",
    "'oil and gax companies',\n",
    "'prescription drug bill',\n",
    "'caliber sniper rifles',\n",
    "'increase the minimum wage',\n",
    "'system of checks and balances',\n",
    "'middle class families',\n",
    "'cut health care',\n",
    "'civil rights movement',\n",
    "'cuts to child support',\n",
    "'drilling in the Arctic National',\n",
    "'victims of gun violence',\n",
    "'solvency of social security',\n",
    "'Voting Rights Act',\n",
    "'war in Iraq and Afghanistan',\n",
    "'civil rights protections',\n",
    "'credit card debt',\n",
    "'Affordable Care Act',\n",
    "'stem cell',\n",
    "'natural gas',\n",
    "'death tax',\n",
    "'illegal aliens',\n",
    "'class action',\n",
    "'war on terror',\n",
    "'embryonic cell',\n",
    "'tax relief',\n",
    "'illegal immigration',\n",
    "'personal account',\n",
    "'pass the bill',\n",
    "'private property',\n",
    "'border security',\n",
    "'human life',\n",
    "'human embryos',\n",
    "'increase taxes',\n",
    "'retirement accounts',\n",
    "'government spending',\n",
    "'national forest',\n",
    "'minority leader',\n",
    "'urge support',\n",
    "'cell lines',\n",
    "'cord blood',\n",
    "'action lawsuits',\n",
    "'economic growth',\n",
    "'food program',\n",
    "'hate crimes legislation',\n",
    "'adult stem cells',\n",
    "'oil for food',\n",
    "'personal retirement accounts',\n",
    "'energy and natural resources',\n",
    "'hate crimes law',\n",
    "'change hearts and minds',\n",
    "'global war on terrorism',\n",
    "'death tax repeal',\n",
    "'housing and urban affairs',\n",
    "'million jobs created',\n",
    "'national flood insurance',\n",
    "'private property rights',\n",
    "'temporary worker program',\n",
    "'class action reform',\n",
    "'growth and job creation',\n",
    "'reform social security',\n",
    "'Obamacare',\n",
    "'president',\n",
    "'george',\n",
    "'bush',\n",
    "'administration',\n",
    "'republican',\n",
    "'democrats',\n",
    "'barack',\n",
    "'obama',\n",
    "'hillary',\n",
    "'clinton',\n",
    "'donald',\n",
    "'trump',\n",
    "'senate',\n",
    "'house'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tagged_doc_pa = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(vocab_political_affiliation)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and saving Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_doc_pa)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    #print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_doc_pa,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "    \n",
    "model.save(\"d2v.model_political.pa\")\n",
    "print(\"Model Saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_statements_d2v=df_train[['statement','label']]\n",
    "model= Doc2Vec.load(\"d2v.model_political.pa\")\n",
    "texts=[]\n",
    "for x in df_train_statements_d2v['statement']:\n",
    "    texts.append(model.infer_vector(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_label(x):\n",
    "    if (x == 'true' or x=='mostly-true' or x=='half-true'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "replace_label('true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(texts)\n",
    "#y=df_train_statements_d2v[['label']]\n",
    "y=df_train_statements_d2v['label'].map(lambda x:replace_label(x))\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y,test_size = .3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr_D2V_PA = LogisticRegression(C=100)\n",
    "logisticRegr_D2V_PA.fit(X_train, y_train)\n",
    "lr_pred_pa = logisticRegr_D2V_PA.predict(X_test)\n",
    "import pickle\n",
    "s = pickle.dumps(logisticRegr_D2V_PA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.25      0.00      0.00      1373\n",
      "          1       0.55      1.00      0.71      1708\n",
      "\n",
      "avg / total       0.42      0.55      0.40      3081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,lr_pred_pa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_D2V_PA = RandomForestClassifier(n_jobs=-1,n_estimators=50,max_depth=90)\n",
    "rf_D2V_PA.fit(X_train,y_train)\n",
    "rf_pred_pa = rf_D2V_PA.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.27      0.33      1373\n",
      "          1       0.55      0.72      0.63      1708\n",
      "\n",
      "avg / total       0.50      0.52      0.49      3081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,rf_pred_pa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def political_affiliation_checker(news):\n",
    "    data_pred=[]\n",
    "    data_pred.append(model.infer_vector(news))\n",
    "    lrg_pa = pickle.loads(s)\n",
    "    pred_conf=lrg_pa.predict_proba(data_pred)\n",
    "    #print(pred_conf)\n",
    "    return pred_conf[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoliticalAffilicationDetector:\n",
    "    def __init__(self,news):\n",
    "        self.news=news\n",
    "    def predict(self):\n",
    "        return political_affiliation_checker(self.news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score for mostly true data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7534285074076726"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "political_affiliation_checker(\"Hillary Clinton agrees with John McCain by voting to give George Bush the benefit of the doubt on Iran.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score for false news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7331134246399988"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "political_affiliation_checker(\"Health care reform legislation is likely to mandate free sex change surgeries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Political Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary for democrat bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "democratic_phrases=['private accounts',\n",
    "'trade agreement',\n",
    "'American people',\n",
    "'tax breaks',\n",
    "'trade deficit',\n",
    "'oil companies',\n",
    "'credit card',\n",
    "'nuclear option',\n",
    "'war in Iraq',\n",
    "'middle class',\n",
    "'President budget',\n",
    "'Republican party',\n",
    "'change the rules',\n",
    "'minimum wage',\n",
    "'budget deficit',\n",
    "'Republican senators',\n",
    "'wildlife refuge',\n",
    "'card companies',\n",
    "'worker\\'s rights',\n",
    "'poor people',\n",
    "'Republican leader',\n",
    "'cut funding',\n",
    "'American workers',\n",
    "'living in poverty',\n",
    "'Senate Republicans',\n",
    "'fuel efficiency',\n",
    "'national wildlife',\n",
    "'veterans health care',\n",
    "'congressional black caucus',\n",
    "'billion in tax cuts',\n",
    "'security trust fund',\n",
    "'social security trust',\n",
    "'privatize social security',\n",
    "'American free trade',\n",
    "'central American free',\n",
    "'corporation for public broadcasting',\n",
    "'additional tax cuts',\n",
    "'pay for tax cuts',\n",
    "'tax cuts for people',\n",
    "'oil and gax companies',\n",
    "'prescription drug bill',\n",
    "'caliber sniper rifles',\n",
    "'increase the minimum wage',\n",
    "'system of checks and balances',\n",
    "'middle class families',\n",
    "'cut health care',\n",
    "'civil rights movement',\n",
    "'cuts to child support',\n",
    "'drilling in the Arctic National',\n",
    "'victims of gun violence',\n",
    "'solvency of social security',\n",
    "'Voting Rights Act',\n",
    "'war in Iraq and Afghanistan',\n",
    "'civil rights protections',\n",
    "'credit card debt',\n",
    "'Affordable Care Act']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary for republican bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "republican_phrases=[\n",
    "'stem cell',\n",
    "'natural gas',\n",
    "'death tax',\n",
    "'illegal aliens',\n",
    "'class action',\n",
    "'war on terror',\n",
    "'embryonic cell',\n",
    "'tax relief',\n",
    "'illegal immigration',\n",
    "'personal account',\n",
    "'pass the bill',\n",
    "'private property',\n",
    "'border security',\n",
    "'human life',\n",
    "'human embryos',\n",
    "'increase taxes',\n",
    "'retirement accounts',\n",
    "'government spending',\n",
    "'national forest',\n",
    "'minority leader',\n",
    "'urge support',\n",
    "'cell lines',\n",
    "'cord blood',\n",
    "'action lawsuits',\n",
    "'economic growth',\n",
    "'food program',\n",
    "'hate crimes legislation',\n",
    "'adult stem cells',\n",
    "'oil for food',\n",
    "'personal retirement accounts',\n",
    "'energy and natural resources',\n",
    "'hate crimes law',\n",
    "'change hearts and minds',\n",
    "'global war on terrorism',\n",
    "'death tax repeal',\n",
    "'housing and urban affairs',\n",
    "'million jobs created',\n",
    "'national flood insurance',\n",
    "'private property rights',\n",
    "'temporary worker program',\n",
    "'class action reform',\n",
    "'growth and job creation',\n",
    "'reform social security',\n",
    "'Obamacare'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_doc_republican = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(republican_phrases)]\n",
    "\n",
    "tagged_doc_democrat = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(democratic_phrases)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing Model for political bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model_dem = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model_dem.build_vocab(tagged_doc_democrat)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    model_dem.train(tagged_doc_democrat,\n",
    "                total_examples=model_dem.corpus_count,\n",
    "                epochs=model_dem.iter)\n",
    "    \n",
    "    model_dem.alpha -= 0.0002\n",
    "    \n",
    "    model_dem.min_alpha = model_dem.alpha\n",
    "    \n",
    "model_dem.save(\"d2v.model_dem.pa\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model_rep = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model_rep.build_vocab(tagged_doc_republican)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model_rep.train(tagged_doc_republican,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model_rep.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model_rep.min_alpha = model.alpha\n",
    "    \n",
    "model.save(\"d2v.model_rep.pa\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_statements_d2v=df_train[['statement','label']]\n",
    "model_dem= Doc2Vec.load(\"d2v.model_dem.pa\")\n",
    "texts=[]\n",
    "for x in df_train_statements_d2v['statement']:\n",
    "    texts.append(model_dem.infer_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_statements_d2v=df_train[['statement','label']]\n",
    "model_rep= Doc2Vec.load(\"d2v.model_rep.pa\")\n",
    "texts=[]\n",
    "for x in df_train_statements_d2v['statement']:\n",
    "    texts.append(model.infer_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_label(x):\n",
    "    if (x == 'true' or x=='mostly-true' or x=='half-true'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "replace_label('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(texts)\n",
    "y=df_train_statements_d2v['label'].map(lambda x:replace_label(x))\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y,test_size = .3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression for political bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr_D2V_DEM = LogisticRegression(C=100)\n",
    "logisticRegr_D2V_DEM.fit(X_train, y_train)\n",
    "lr_pred_dem = logisticRegr_D2V_DEM.predict(X_test)\n",
    "import pickle\n",
    "s = pickle.dumps(logisticRegr_D2V_DEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr_D2V_REP = LogisticRegression(C=100)\n",
    "logisticRegr_D2V_REP.fit(X_train, y_train)\n",
    "lr_pred_rep = logisticRegr_D2V_REP.predict(X_test)\n",
    "import pickle\n",
    "s = pickle.dumps(logisticRegr_D2V_REP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.00      0.00      1373\n",
      "          1       0.55      1.00      0.71      1708\n",
      "\n",
      "avg / total       0.53      0.55      0.40      3081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,lr_pred_dem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.00      0.00      1373\n",
      "          1       0.55      1.00      0.71      1708\n",
      "\n",
      "avg / total       0.53      0.55      0.40      3081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,lr_pred_rep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest for political bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_D2V_DEM = RandomForestClassifier(n_jobs=-1,n_estimators=50,max_depth=90)\n",
    "rf_D2V_DEM.fit(X_train,y_train)\n",
    "rf_pred_dem = rf_D2V_DEM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.27      0.34      1373\n",
      "          1       0.56      0.73      0.63      1708\n",
      "\n",
      "avg / total       0.51      0.53      0.50      3081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,rf_pred_dem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def political_affiliation_democrat(news):\n",
    "    data_pred=[]\n",
    "    data_pred.append(model.infer_vector(news))\n",
    "    lrg_dem = pickle.loads(s)\n",
    "    pred_conf=lrg_dem.predict_proba(data_pred)\n",
    "    #print(pred_conf)\n",
    "    return pred_conf[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoliticalBiasDemocrat:\n",
    "    def __init__(self,news):\n",
    "        self.news=news\n",
    "    def predict(self):\n",
    "        return political_affiliation_democrat(self.news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_D2V_REP = RandomForestClassifier(n_jobs=-1,n_estimators=50,max_depth=90)\n",
    "rf_D2V_REP.fit(X_train,y_train)\n",
    "rf_pred_rep = rf_D2V_REP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.26      0.33      1373\n",
      "          1       0.55      0.74      0.63      1708\n",
      "\n",
      "avg / total       0.50      0.52      0.50      3081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,rf_pred_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def political_affiliation_republic(news):\n",
    "    data_pred=[]\n",
    "    data_pred.append(model.infer_vector(news))\n",
    "    lrg_pa = pickle.loads(s)\n",
    "    pred_conf=lrg_pa.predict_proba(data_pred)\n",
    "    #print(pred_conf)\n",
    "    return pred_conf[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoliticalBiasRepublic:\n",
    "    def __init__(self,news):\n",
    "        self.news=news\n",
    "    def predict(self):\n",
    "        return political_affiliation_republic(self.news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating score for random news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"McCain opposed a requirement that the government buy American-made motorcycles. And he said all buy-American provisions were quote 'disgraceful.' \"\n",
      "true   democrat\n",
      "------------\n",
      "0.7900135943686248\n",
      "0.6985716476754903\n",
      "0.7475885967516733\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train['statement'][16])\n",
    "print(dataset_train['label'][16],' ',dataset_train['party_affiliation'][16])\n",
    "print('------------')\n",
    "print(political_affiliation_checker(dataset_train['statement'][16]))\n",
    "print(political_affiliation_republic(dataset_train['statement'][16]))\n",
    "print(political_affiliation_democrat(dataset_train['statement'][16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Mitt Romney was governor of Massachusetts, we didnt just slow the rate of growth of our government, we actually cut it.\n",
      "false   republican\n",
      "------------\n",
      "0.8456202713659947\n",
      "0.8276168124941033\n",
      "0.7533353080817765\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train['statement'][12])\n",
    "print(dataset_train['label'][12],' ',dataset_train['party_affiliation'][12])\n",
    "print('------------')\n",
    "\n",
    "print(political_affiliation_checker(dataset_train['statement'][12]))\n",
    "print(political_affiliation_republic(dataset_train['statement'][12]))\n",
    "print(political_affiliation_democrat(dataset_train['statement'][12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vidya Nand Kumar Coimbatore - Controversy Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_doc2vec=['abus','account','administr','advantag','afghanistan','aid','america','american','amount','armi','attack','attorney','author','ban','bank','benefit','bill','border','budget','campaign','candid','cathol','chairman','charg','china','chines','church','citi','class','comment','compani','concern','congress','conserv','control','cost','countri','court','credit','crime','crimin','crisi','cut','debat','debt','defens','deficit','delay','democrat','diseas','dollar','drug','economi','educ','effect','egypt','elect','enforc','expect','famili','februari','fight','financ','fiscal','forc','fund','ga','germani','goal','govern','gun','health','hous','immigr','inaccuraci','india','inform','insur','invest','investig','iran','israel','job','judg','justic','kill','korea','labor','land','law','lawmak','lawsuit','leadership','legisl','market','marriag','media','mexico','militari','money','murder','nation','news','number','obama','offens','offici','oil','oklahoma','parent','parti','patient','peac','polic','polici','polit','poll','popul','power','presid','price','primari','prison','progress','project','race','rais','rate','reason','reform','republican','restrict','rule','russia','russian','sale','school','sector','secur','senat','sex','shoot','shot','societi','sourc','spend','statu','stock','store','strategi','strike','support','syria','syrian','tax','threat','trial','unemploy','union','usa','victim','violenc','vote','voter','war','washington','weapon','whether','world','worth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_doc_2vec = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(vocab_doc2vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_doc_2vec)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "   \n",
    "    model.train(tagged_doc_2vec,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "   \n",
    "    model.alpha -= 0.0002\n",
    "    \n",
    "    model.min_alpha = model.alpha\n",
    "    \n",
    "model.save(\"doc2vec_model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_statements_d2v=train_df_doc[['statement','label']]\n",
    "model_dem= Doc2Vec.load(\"doc2vec_model\")\n",
    "texts=[]\n",
    "for x in df_train_statements_d2v['statement']:\n",
    "    texts.append(model_dem.infer_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_label(x):\n",
    "    if (x == 'true' or x=='mostly-true' or x=='half-true'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "replace_label('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(texts)\n",
    "y=df_train_statements_d2v['label'].map(lambda x:replace_label(x))\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y,test_size = .3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr_doc2Vec = LogisticRegression(C=100)\n",
    "logisticRegr_doc2Vec.fit(X_train, y_train)\n",
    "pred = logisticRegr_doc2Vec.predict(X_test)\n",
    "import pickle\n",
    "s = pickle.dumps(logisticRegr_doc2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.91      0.70       255\n",
      "          1       0.46      0.10      0.16       195\n",
      "\n",
      "avg / total       0.52      0.56      0.47       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_doc2vec = RandomForestClassifier(n_jobs=-1,n_estimators=50,max_depth=90)\n",
    "rf_doc2vec.fit(X_train,y_train)\n",
    "rf_pred = rf_doc2vec.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.86      0.68       255\n",
      "          1       0.42      0.13      0.20       195\n",
      "\n",
      "avg / total       0.50      0.54      0.47       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def controversy_checker(news):\n",
    "    data_pred=[]\n",
    "    data_pred.append(model.infer_vector(news))\n",
    "    lrg_pa = pickle.loads(s)\n",
    "    pred_conf=lrg_pa.predict_proba(data_pred)\n",
    "    #print(pred_conf)\n",
    "    return pred_conf[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControversyDetector:\n",
    "    def __init__(self,news):\n",
    "        self.news=news\n",
    "    def predict(self):\n",
    "        return controversy_checker(self.news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44763847494470127"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controversy_checker(\"say anni list polit group support trimest abort demand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anjana Kamath Miyar - Topic features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "countV = CountVectorizer()\n",
    "train_count = countV.fit_transform(train_df['statement'].values)\n",
    "y_train = train_df['label']\n",
    "\n",
    "test_count =  countV.transform(test_data['statement'].values)\n",
    "y_test = test_data['label']\n",
    "\n",
    "tfidfV = TfidfVectorizer()\n",
    "train_tfidf = tfidfV.fit_transform(train_df['statement'].values)\n",
    "test_tfidf =  tfidfV.transform(test_data['statement'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "clf = MultinomialNB() \n",
    "clf.fit(train_tfidf, y_train)\n",
    "pred = clf.predict(test_tfidf)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.634\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression() \n",
    "log_clf.fit(train_tfidf, y_train)\n",
    "pred = log_clf.predict(test_tfidf)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.613\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_clf = svm.LinearSVC() \n",
    "svm_clf.fit(train_tfidf, y_train)\n",
    "pred = svm_clf.predict(test_tfidf)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "pa_clf = PassiveAggressiveClassifier(n_iter=50)\n",
    "pa_clf.fit(train_tfidf, y_train)\n",
    "pred = pa_clf.predict(test_tfidf)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.613\n"
     ]
    }
   ],
   "source": [
    "rfc_clf = RandomForestClassifier()\n",
    "rfc_clf.fit(train_tfidf, y_train)\n",
    "pred = rfc_clf.predict(test_tfidf)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_detection(var):    \n",
    "#retrieving the best model for prediction call\n",
    "    load_model = pickle.load(open('final_model.sav', 'rb'))\n",
    "    prediction = load_model.predict([var])\n",
    "    prob = load_model.predict_proba([var])\n",
    "    #print(\"The given statement is \",prediction[0])\n",
    "    #print(\"The truth probability score is \",prob[0][1])\n",
    "    return prob[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given statement is  True\n",
      "The truth probability score is  0.568017336920146\n"
     ]
    }
   ],
   "source": [
    "input_news = 'Building a wall on the U.S.-Mexico border will take literally years'\n",
    "detecting_fake_news(input_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the maximum accuracy calculated by running the above algorithms I chose topic features factor to be of 0.64 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Polynomial Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fakedetection(news_article):\n",
    "    \n",
    "    sensationalism_factor= detect_sensationalism_calc(news_article)\n",
    "    \n",
    "    political_affiliation_republic_factor= political_affiliation_republic(news_article)\n",
    "    political_affiliation_democrat_factor = political_affiliation_democrat(news_article)\n",
    "    political_affiliation_checker_factor = political_affiliation_checker(news_article)\n",
    "\n",
    "    controversy_checker_factor = controversy_checker(news_article)\n",
    "    \n",
    "    topic_features_factor = features_detection(news_article)\n",
    "    \n",
    "    sensationalism_weight=.26\n",
    "    political_affilication_republic_weight= 0.3\n",
    "    political_affilication_democrat_weight = 0.4\n",
    "    controversy_checker_weight=.25\n",
    "    topic_features_factor_weight = 0.40\n",
    "    \n",
    "    print('sensationalism_factor:',sensationalism_factor)\n",
    "    print('political_bias_republic_factor:',political_affiliation_republic_factor)\n",
    "    print('political_bias_democrat_factor:',political_affiliation_democrat_factor)\n",
    "    print('political_affiliation_checker_factor:',political_affiliation_checker_factor)\n",
    "    print('controversy_checker_factor:',controversy_checker_factor)\n",
    "    print('topic_features_factor:',topic_features_factor)\n",
    "    total_perc_weight = sensationalism_weight+political_affilication_republic_weight+political_affilication_democrat_weight+political_affilication_checker_weight+ controversy_checker_weight+topic_features_factor_weight\n",
    "    \n",
    "    return ((sensationalism_factor*sensationalism_weight)+\n",
    "            (political_affiliation_republic_factor*political_affilication_republic_weight)+\n",
    "            (political_affiliation_democrat_factor*political_affilication_democrat_weight)+\n",
    "            (political_affiliation_checker_factor*political_affilication_checker_weight)+\n",
    "            (controversy_checker_factor*controversy_checker_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating True News\n",
    "* We took false news from test data and checked with our fake news detection function. The values we got were close to 0 and it showed that the news is closer to being true.That is false probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensationalism_factor: 0.32954110681275695\n",
      "political_bias_republic_factor: 0.2657501496052827\n",
      "political_bias_democrat_factor: 0.31977115047872084\n",
      "political_affiliation_checker_factor: 0.3579305842509412\n",
      "controversy_checker_factor: 0.32344675267465894\n",
      "topic_features_factor: 0.5366298204400898\n",
      "\u001b[1mprobability of news to be false \u001b[1m 0.3741758810130547\n"
     ]
    }
   ],
   "source": [
    "input_news = 'Each year, 18,000 people die in America because they dont have health care'\n",
    "print('\\033[1m' +'probability of news to be false '+'\\033[1m',fakedetection(input_news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensationalism_factor: 0.44787472588807736\n",
      "political_bias_republic_factor: 0.3606545126394851\n",
      "political_bias_democrat_factor: 0.40699627765655344\n",
      "political_affiliation_checker_factor: 0.4006949085818859\n",
      "controversy_checker_factor: 0.4154589177345162\n",
      "topic_features_factor: 0.568017336920146\n",
      "\u001b[1mprobability of news to be false \u001b[1m 0.4913070230189961\n"
     ]
    }
   ],
   "source": [
    "input_news = 'Building a wall on the U.S.-Mexico border will take literally years'\n",
    "print('\\033[1m' +'probability of news to be false '+'\\033[1m',fakedetection(input_news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating False News \n",
    "* We took false news from test data and checked with our fake news detection function. The values we got were close to one and it gave the percentage of falsity in the news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensationalism_factor: 0.37573535788536233\n",
      "political_bias_republic_factor: 0.37843643548350486\n",
      "political_bias_democrat_factor: 0.3424823517760719\n",
      "political_affiliation_checker_factor: 0.39406114477252097\n",
      "controversy_checker_factor: 0.3598124218843832\n",
      "topic_features_factor: 0.5835102088200236\n",
      "\u001b[1mprobability of news to be false \u001b[1m 0.8500470353171607\n"
     ]
    }
   ],
   "source": [
    "input_news = 'Says John McCain has done nothing to help the vets'\n",
    "print('\\033[1m' +'probability of news to be false '+'\\033[1m',fakedetection(input_news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensationalism_factor: 0.32635613699711863\n",
      "political_bias_republic_factor: 0.34332511439263347\n",
      "political_bias_democrat_factor: 0.3788256707271877\n",
      "political_affiliation_checker_factor: 0.3115139203438204\n",
      "controversy_checker_factor: 0.38590214228785774\n",
      "topic_features_factor: 0.5957055348392479\n",
      "\u001b[1mprobability of news to be false \u001b[1m 0.8071086526720894\n"
     ]
    }
   ],
   "source": [
    "input_news = 'Wisconsin is on pace to double the number of layoffs this year'\n",
    "print('\\033[1m' +'probability of news to be false '+'\\033[1m',fakedetection(input_news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each individual factor was given a weight depending on the factor score we got by carrying out various algorithms.\n",
    "* Sensationalism score was computed by applying LDA using TF-IDF, BOW, Word2Vec sentiment analysis ,cosine similarity and Doc2Vec. Trained a model using the sensationalism score and variation and got a weightage of 0.58 which gave maximum accuracy of 0.41 using Random Forest Classifier.\n",
    "* Political Affiliation gave republican and democratic score based on the algorithms performed on it - sentiment analysis, Doc2Vec, BOW, LDA and cosine similarity. Trained the model using republican and democratic score and got a weightage of 0.22 with an accuracy of 0.65 using Random Forest Classifier.\n",
    "* Controversy score was computed by applying Doc2Vec, LDA, BOW and cosine similarity. The model was trained using Random Forest Classifier, which provided threshold as 0.27 and maximum accuracy as 0.51.\n",
    "\n",
    "* After getting the weightages for each factor we applied doc2vec to determine the truth or false depending on each factor.\n",
    "* Percentages of each factor gave us the percentage of falsity and truth in the news.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
